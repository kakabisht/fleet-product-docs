= Rollout Strategy

{product_name} uses a rollout strategy to control how apps are deployed across clusters. You can define the order and grouping of cluster deployments using partitions, enabling controlled rollouts and safer updates.

{product_name} evaluates the `Ready` status of each `BundleDeployment` to determine when to proceed to the next partition. For more information, refer to xref:ref-status-fields.adoc[Status Fields].

During a rollout, the GitRepo status indicates deployment progress. This helps you understand when bundles become `Ready` before continuing:

* For initial deployments:
 ** One or more clusters may be in a `NotReady` state.
 ** Remaining clusters are marked as `Pending`, meaning deployment has not started.
* For rollouts:
 ** One or more cluster may be in a `NotReady` state.
 ** Remaining clusters are marked `OutOfSync` until the deployment continues.

The rollout configuration options are documented in the xref:ref-fleet-yaml.adoc[`rolloutStrategy` field of the `fleet.yaml` reference].

[NOTE]
====
If `rolloutStrategy` is not specified in `fleet.yaml`, it uses the default values.
====


== How Does Partitioning Work?

Partitions are solely used for grouping and controlling the rollout of `BundleDeployments` across clusters. They do not affect deployment options in any way.

If targeted clusters are not part of the manual partitioning, they will not be included in the rollout. If a cluster is part of a partition, it will receive a `BundleDeployment` when the partition is processed.

Partitions are considered `NotReady` if they have clusters that exceed the allowed number of `NotReady` clusters. If a cluster is offline, the targeted cluster will not be considered `Ready` and will stay in the `NotReady` state until it comes back online and successfully deploys the `BundleDeployment`.

The threshold is determined by:

* *Manual partitions*: Use `maxUnavailable` value inside each partition to control readiness for that partition, otherwise, if unspecified, it uses `rolloutStrategy.maxUnavailable`.
* *Automatic partitions*: Use `rolloutStrategy.maxUnavailable` value to control when a partition is ready.

{product_name} proceeds only if the number of `NotReady` partitions remains below `maxUnavailablePartitions`.

[NOTE]
====
{product_name} rolls out deployments in batches of up to 50 clusters per partition, regardless of partitions having more clusters assigned. After each batch, {product_name} checks the `maxUnavailable` threshold before continuing. After all deployments for a partition have been created, `maxUnavailable` is also evaluated. For example:

* If a partition has 25 clusters and `maxUnavailable` is 5, {product_name} deploys to all 25 before checking `maxUnavailable`.
* If a partition has 100 clusters, {product_name} deploys to the first 50, checks `maxUnavailable`, and proceeds with the remaining 50 only if the threshold is not exceeded.
====

The following diagram displays how to handle rollout:

image::/images/flow-rollout-fleet.png[A visual asset displaying flow of rollout in Fleet.]

Various limits that can be configured are:

|===
| Field | Description | Default

| maxUnavailable
| Maximum number or percentage of clusters that can be `NotReady` before halting rollout.
| 100%

| maxUnavailablePartitions
| Number or percentage of partitions that can be `NotReady` at once.
| 0

| autoPartitionSize
| Number or percentage of clusters per auto-created partition.
| 25%

| partitions
| Define manual partitions by cluster labels or group. If set, autoPartitionSize is ignored.
| --
|===

{product_name} supports automatic and manual partitioning. For more information about configuration options, refer to the xref:ref-fleet-yaml.adoc[`rolloutStrategy` option in the fleet.yaml reference.]
*Automatic Partitioning*: {product_name} automatically creates partitions using `autoPartitionSize`.
+
For example, you have 200 clusters and set `autoPartitionSize` to 25%, it creates four partitions of 50 clusters each. Rollout proceeds in 50-cluster batches, checking `maxUnavailable` before continuing.
+
*Manual Partitioning*: You define specific partitions using the `partitions` option. This provides control over cluster selection and rollout order.

[NOTE]
====
If you specify partitions manually, the `autoPartitionSize` is ignored.
====

For example, consider:

[,yaml]
----
rolloutStrategy:
  partitions:
    - name: demoRollout
      maxUnavailable: 10%
      clusterSelector:
        matchLabels:
          env: staging
    - name: stable
      maxUnavailable: 5%
      clusterSelector:
        matchLabels:
          env: prod
----

It then:

. Selects clusters based on `clusterSelector`, `clusterGroup`, or `clusterGroupSelector`.
 ** Partitions can be specified by `clusterName`, `clusterSelector`, `clusterGroup`, and `clusterGroupSelector`.
. Starts rollout to the first partition.
. Waits until the partition is considered `Ready` (depending on the `maxUnavailable` threshold).
. Proceeds to the next partition.

The following diagram illustrates how to handle rollout across multiple partitions, including readiness checks and deployment flow:

image::/images/deploy-targets-partition.png[A visual asset displaying the flow of partition rollout]

[NOTE]
====
MaxNew is always 50. A bundle change can only stage 50 `BundleDeployments` at a time.	
====

Within each partition, {product_name} rolls out up to 50 `BundleDeployments` at a time. The diagram below shows how {product_name} determines whether to proceed or wait during this process:

image::/images/partition-rollout-flow.png[A visual asset displaying the flow of deploying targets in a partition]

==

[NOTE]
====
{product_name} recommends labeling clusters so you can use those labels to assign clusters to specific partitions.
====


[NOTE]
====
{product_name} processes partitions in the order they appear in the `fleet.yaml` file.
====

=== Single Partition

If you don't define `rolloutStrategy.partitions`, {product_name} creates partitions automatically based on the number of targeted clusters:

* For fewer than 200 clusters, it uses a single partition.
* For 200 or more clusters, it uses the default `autoPartitionSize` value (25%) of the total.

For example, consider 200 clusters, {product_name} uses the default `autoPartitionSize` of 25%. This means, it creates 4 partitions (25% of 200 = 50 clusters per partition). {product_name} processes up to 50 clusters at a time, which means it:

. Rolls out to the first 50 clusters.
. Evaluate readiness based on `maxUnavailable`.
. If the condition is met, proceed to the next 50, and so on.

=== Multiple Partitions

If you define multiple partitions, {product_name} uses `maxUnavailablePartitions` to limit how many partitions can be `NotReady` at once. If the number of `NotReady` partitions exceeds `maxUnavailablePartitions`, {product_name} pauses the rollout.

== Preventing image pull storms

During rollout, each downstream cluster pulls container images. If hundreds of clusters begin pulling images simultaneously, this can overwhelm the registry and behave like a DDoS attack.

To avoid this, you can control how many clusters are updated at a time. You can use the following rollout configuration options to slow down and stage the rollout:

* `autoPartitionSize`
* `partitions`
* `maxUnavailable`

This does not add artificial delays during rollout. Instead, it proceeds based on the `readiness` status of workloads in each cluster. Factors that affect readiness include image pull time, startup time, and readiness probes. Although using readiness probes is recommended, they are not strictly required to control rollout speed.

For example, you have 200 clusters, which are manually partitioned, each with 40 clusters and want to prevent an image pull storm:

* `maxUnavailablePartitions`: Set to 0.
* `maxUnavailable`: Set to 10%.

How rollout proceeds:

. {product_name} begins with the first partition (40 clusters).
. It deploys up to 50 `BundleDeployments` at once. So it deploys to all 40 clusters in the partition in one batch.
. {product_name} checks the readiness of clusters in the partition.
. If more than 4 clusters are not ready, then the partition is considered `NotReady` and the rollout is paused.
. Once â‰¤4 clusters are `NotReady`, {product_name} proceeds with the deployment.
. When the entire partition is mostly ready (90%), {product_name} moves to the next partition.

If you want or need to process fewer than 40 deployments at once, you can put fewer clusters into each partition.

== Use Cases and Behavior

If the number of clusters doesn't divide evenly, it rounds down partition sizes. For example, 230 clusters with `autoPartitionSize: 25%` results in:

* Four partitions of 57 clusters
* One partition of 2 clusters

=== Scenario: 50 Clusters (Single Partition)

[,yaml]
----
rolloutStrategy:
  maxUnavailable: 10%
----

* You create one partition containing all 50 clusters, since no partitions are defined.
 ** No requirement to specify `maxUnavailablePartitions`, as only one partition is created.
* Although there is no specified manual partition and `maxUnavailable` is set to 10% and deploys to all 50 clusters at once (batch behavior overrides `maxUnavailable` initially).
* Evaluation occurs after all deployments are created.

The following diagram illustrates how to handle 50 clusters in a single partition:

image::/images/deploy-50Clusters.png[A visual asset displaying 50 clusters]

=== Scenario: 100 Clusters (Single Partition)

[,yaml]
----
rolloutStrategy:
  maxUnavailable: 10%
----

* You create one partition containing all 100 clusters, since no partitions are defined.
 ** No requirement to specify `maxUnavailablePartitions`, as you have only one.
* Although there is no specified manual partition and `maxUnavailable` is set to 10% and deploys to 50 clusters at once (batch behavior overrides `maxUnavailable` initially).

If 10 clusters (10% of 100 clusters) are unavailable, the deployment of the remaining 50 clusters is paused until less than 10 clusters are `NotReady`.

=== Scenario: 200 Clusters (Multiple Partitions)

[,yaml]
----
rolloutStrategy:
  maxUnavailablePartitions: 1
  autoPartitionSize: 10%
----

* You create 10 partitions, each with 20 clusters.
* Deployment proceeds sequentially by partition.
* If two or more partitions become `NotReady`, rollout pauses.
* If one partition is `NotReady`, rollout can proceed to the next.

{product_name} creates `BundleDeployments` for 20 clusters, waits for them to become `Ready`, then proceeds to the next. This effectively limits the amount of image pulls from downstream clusters to up to ~40 images at a time.

=== Scenario: 200 Clusters (Strict Readiness, Manual partitions)

Manual partitioning allows you control over cluster grouping with `maxUnavailablePartitions: 0`.

[,yaml]
----
rolloutStrategy:
  maxUnavailable: 0
  maxUnavailablePartitions: 0
  partitions:
    - name: demoRollout
      clusterSelector:
        matchLabels:
          stage: demoRollout
    - name: stable
      clusterSelector:
        matchLabels:
          stage: stable
----

* You define manual partitions using `clusterSelector` and labels like `stage: demoRollout` and `stage: stable`.
* You create `BundleDeployments` for clusters in the first partition (for example, `demoRollout`).
* The rollout proceeds strictly in order, you only moves to the next partition when the current one is considered ready.
* With `maxUnavailable: 0` and `maxUnavailablePartitions: 0`, {product_name} pauses the rollout if any partition is not considered ready.

The following diagram describes how to handle whether to continue or pause rollout.

image::/images/partition-fleet-rollout.png[A visual asset displaying the partitions about rollout in Fleet]

This ensures full readiness and staged rollout across all 200 clusters. Use this approach when you need precise rollout sequencing and full cluster readiness before advancing.

== Rollout Strategy Defaults

If partition-level rollout values are not defined, {product_name} applies the global values from `rolloutStrategy` in `fleet.yaml`. Partition-specific settings override global values when explicitly set.

By default, the values are set:

* `maxUnavailable` to `100%`: All clusters in a partition can be `NotReady` and still be considered Ready.
* `maxUnavailablePartitions` to `0`: Prevents rollout only when one or more partitions are considered `NotReady`. However, this check is ineffective if all partitions appear Ready due to `maxUnavailable: 100%`.

For example, consider 200 clusters with default settings:

* {product_name} creates 4 partitions of 50 clusters each (`autoPartitionSize: 25%`).
* Because `maxUnavailable` is `100%`, each partition is treated as `Ready` immediately.
* {product_name} proceeds through all partitions regardless of actual readiness.

{product_name} recommends you to control rollouts by setting:

* Lower `maxUnavailable`, e.g. 10%.
* Set `maxUnavailablePartitions` to 0 or higher, if desired.

This ensures:

* Partitions meet readiness before rollout continues.
* {product_name} pauses rollout if too many partitions are not ready.
